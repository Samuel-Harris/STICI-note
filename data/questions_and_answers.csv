index,document_index,multisource,question,answer
0,0,False,"What do keybullet kin drop?","Keybullet kin drop a key upon death."
1,0,False,"What kind of gun does the bandana bullet kin use?","The bandana bullet kin wields a machine pistol."
2,0,True,"Which enemy types wield an AK-47?","Assault-rifle wielding Bullet and Tankers wield AK-47s."
3,0,True,"What makes jammed enemies different?","Jammed Keybullet Kin drop 2 keys instead of 1, jammed Chance Kins have a chance to drop twice the loot, and jammed red-Caped Bullet Kin deal contact damage. Additionally, Jammed Keybullet Kin Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly."
4,1,False,"What do the giants look like?","One giant is burly, grey-skinned, and 20 feet tall. It wears heavy dark iron armour covered in metal torns. It is leaning against a chamber wall, carrying what looks to be two tower shields nearly as tall as itself, both bearing
menacing spikes.

The other giant  stands a tall giant in more mobile iron, clutching a dangerous-looking maul the size of Yasha, also leaning and looking disinterested."
5,1,False,"What happens on day 2?","After a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area.

You encounter 2 ropers seeking the next burrowed entrance left by the Kryn."
6,1,True,"What enemies are encountered in the second encounter?","26 kobolds and 1 kobold inventor are encountered in the second encounter."
7,1,True,"What monsters are encountered in this journey?","Ropers, kobolds, kobold inventors, fire giants, and fire giant dreadnoughts."
8,2,False,"What were the requirements for the project?","The tool had the following requirements:
- Chatbot that you can ask questions and get answers in response (conversational memory is not required).
- Information is taken from an unstructured text file.
- It must be able to tell me if it doesnâ€™t know the answer to my question.
- Fast.
- Efficient enough to run on my MacBook with other programs without any performance issues.
- Locally run for privacy and to ensure it will always be free, runnable, and consistent."
9,2,False,"What data did was used to test the prototype?","Grace Hopper's Wikipedia page and Alan Turing's Wikipedia page were used to test the prototype."
10,2,True,"What framework was chosen to execute the RAG process and what alternatives were considered?","The LangChain framework was used to orchestrate the RAG process. Llamaindex and LitGPT were also considered during development. Llmware was considered after development had finished."
11,2,True,"Which large language models and vector databases were shortlisted for this project?","The tinyllama-1.1b-chat-v1.0 Q6_K, Phi 3 Q4_K_M"", bartowski/dolphin-2.8-experiment26-7b-GGUF Q3_K_L, mgonzs13/Mistroll-7B-v2.2-GGU, and QuantFactory/Meta-Llama-3-8B-Instruct Q3_K_M large language models and the Chroma, Qdrant, and Vespa vector databases were shortlisted for this project."
12,3,False,"How do the data storage options compare?","For fast start: use SQLite3 and ChromaDB (File-based) out-of-the-box - no install required.
For speed + scale: use MongoDB (text collection) and Milvus (vector db) - install with Docker Compose
For postgres: use Postgres for both text collection and vector DB - install with Docker Compose
For mix-and-match: LLMWare supports 3 text collection databases (Mongo, Postgres, SQLite) and 10 vector databases (Milvus, PGVector-Postgres, Neo4j, Redis, Mongo-Atlas, Qdrant, Faiss, LanceDB, ChromaDB and Pinecone)"
13,3,False,"When was UTF-8 support added for European languages?","Wednesday 3rd April in the v0.2.7 Update"
14,3,True,"What kind of model is the bling-phi-3 model","The bling-phi-3 model is the newest and most accurate BLING/DRAGON model. BLING models are small CPU-based RAG-optimized, instruct-following 1B-3B parameter models. DRAGON models are production-grade RAG-optimized 6-7B parameter models - "Delivering RAG on ..." the leading foundation base models."
15,3,True,"In which versions were the SLIM models updated?","The SLIM models were updated in versions 0.2.3, 0.2.6, 0.2.12, 0.3.0, and 0.3.1"
16,4,False,"",
17,4,False,,
18,4,True,,
19,4,True,,
20,5,False,,
21,5,False,,
22,5,True,,
23,5,True,,
24,6,False,,
25,6,False,,
26,6,True,,
27,6,True,,
28,7,False,,
29,7,False,,
30,7,True,,
31,7,True,,
32,8,False,,
33,8,False,,
34,8,True,,
35,8,True,,
36,9,False,,
37,9,False,,
38,9,True,,
39,9,True,,
40,10,False,,
41,10,False,,
42,10,True,,
43,10,True,,
44,11,False,,
45,11,False,,
46,11,True,,
47,11,True,,
48,12,False,,
49,12,False,,
50,12,True,,
51,12,True,,
52,13,False,,
53,13,False,,
54,13,True,,
55,13,True,,
56,14,False,,
57,14,False,,
58,14,True,,
59,14,True,,
60,15,False,,
61,15,False,,
62,15,True,,
63,15,True,,
64,16,False,,
65,16,False,,
66,16,True,,
67,16,True,,
68,17,False,,
69,17,False,,
70,17,True,,
71,17,True,,
72,18,False,,
73,18,False,,
74,18,True,,
75,18,True,,
76,19,False,,
77,19,False,,
78,19,True,,
79,19,True,,
80,19,False,,
81,19,False,,
82,19,True,,
83,19,True,,