{
    "model_path": [
      "models/model_weights/tinyllama-1.1b-chat-v1.0.Q6_K.gguf",
      "models/model_weights/Phi-3-mini-4k-instruct-q4.gguf",
      "models/model_weights/dolphin-2.8-experiment26-7b-Q3_K_L.gguf",
      "models/model_weights/Mistroll-7B-v2.2.IQ4_XS.gguf",
      "models/model_weights/Meta-Llama-3-8B.Q3_K_M.gguf"
    ],
    "temperature": [0],
    "top_p": [1],
    "top_k": [32]
  }